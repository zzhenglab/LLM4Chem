# **Large Language Models for Chemists: Applications and Insights**

<div style="max-width: 800px; margin: auto; text-align: justify;">

This digital resource accompanies the book **Large Language Models for Chemists: Applications and Insights**, which introduces how large language models (LLMs) are beginning to transform the practice of chemistry. Over the past decade, chemists have seen data science and machine learning evolve from niche interests into everyday tools for prediction, modeling, and discovery. What sets LLMs apart is their remarkable flexibility: they can not only parse chemical data but also interpret, explain, and generate human-readable text, bridging the gap between raw numbers and scientific communication. Chemistry itself is a language—of molecules, reactions, and data—and LLMs offer a way to accelerate the work of students, researchers, and educators alike. They can simplify complex concepts, distill vast amounts of literature, draft code, create teaching materials, and even propose new hypotheses. More than tools for analyzing molecules, they are partners for chemists, helping us think faster, learn deeper, and communicate more effectively.

The story of AI in chemistry stretches back to expert systems like **DENDRAL** and **LHASA**, which attempted to encode rules for interpreting spectra and planning syntheses, followed by data-driven QSAR models that used statistics to predict properties like solubility or toxicity. These efforts demonstrated the promise of computation but were often limited in scope. The turning point came with transformer architectures in 2017, which enabled models such as BERT and GPT to learn language at scale. Chemistry, with its structured grammar of molecular formulas, SMILES strings, and reaction equations, is itself a language—making it a natural fit for these models. Today, LLMs such as GPT, Claude, Gemini, DeepSeek, and LLaMA can summarize papers, draft lab protocols, generate chemical insights, and integrate with external tools. Unlike traditional AI systems built for narrow tasks, LLMs are generalists whose greatest strength lies in integration—bridging the gap between information and insight. That is why this resource exists: to help chemists understand, experiment with, and ultimately benefit from LLMs in their pursuit of discovery.  

</div>


## Table of Contents  

```{tableofcontents}
```

## Digital Resource

- **Chapter 3** – Foundations of AI and Tools for Chemists   [![Colab](https://img.shields.io/badge/Open-Colab-orange)](https://colab.research.google.com/drive/17MRb43WSp2KErf6tMBlge18CBBPv4LpJ?usp=sharing) 
- **Chapter 4** – Large Language Models in Chemistry  [![Colab](https://img.shields.io/badge/Open-Colab-orange)](https://colab.research.google.com/drive/1_egNwLz0vgRQiVOOnz9Ojen2VO9S90rt?usp=sharing) 
- **Chapter 5** – Literature and Knowledge Mining with LLMs  [![Colab](https://img.shields.io/badge/Open-Colab-orange)](https://colab.research.google.com/drive/1S-86J9lEIN7FYOl23cPRQ6zrpcFHobeH?usp=sharing) 
- **Chapter 6** – Generative Models for Molecule and Materials Design  [![Colab](https://img.shields.io/badge/Open-Colab-orange)](https://colab.research.google.com/drive/1cm9ymXHkl1rzbZrvRLR6YxaxZn4rI7Rs?usp=sharing) 
- **Chapter 7** – LLMs and Automation  [![Colab](https://img.shields.io/badge/Open-Colab-orange)](https://colab.research.google.com/drive/1mn-zuTJnGpEHHts37uIo0UfFBmTaDgFw?usp=sharing) 


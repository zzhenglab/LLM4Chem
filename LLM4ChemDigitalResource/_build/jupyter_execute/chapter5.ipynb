{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKq_tqe_9rkT"
   },
   "source": [
    "## **Chapter 5 – Literature and Knowledge Mining with LLMs**\n",
    "\n",
    "The explosion of chemical literature has made it difficult for researchers to keep up with new findings. Large language models (LLMs) provide a powerful way to mine this vast knowledge. This chapter explores how LLMs transform literature interaction, starting with the scale and complexity of today’s journals and the limits of manual or rule-based mining. We then cover automated techniques powered by LLMs—such as chemical named entity recognition, relationship extraction, and parsing of experimental sections.  \n",
    "\n",
    "We further show how extracted data can form **knowledge bases or graphs**, organizing reactions, properties, and relationships beyond traditional databases. LLM-driven analysis of literature can also inspire new hypotheses and guide research directions. Practical examples, code snippets, and case studies demonstrate these ideas, highlighting that LLMs are not just tools for text, but catalysts for **knowledge discovery in chemistry**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ttBmW_ge8dR"
   },
   "source": [
    "### 5.2.1 Entity and Relationship Extraction  \n",
    "\n",
    "A core task in text mining is **entity extraction**—identifying mentions of key items within text. In chemistry, these entities often include compounds, materials, reactions, properties, experimental conditions, and instruments. For example, **chemical named entity recognition (CNER)** targets chemical names such as *aspirin*, *H₂SO₄*, or *acetylsalicylic acid*.  \n",
    "\n",
    "Building on this, **relationship extraction** identifies how entities connect. Examples include linking a compound to a property (*“aspirin has a melting point of 135 °C”*) or mapping reagents to a reaction outcome (*“benzene under condition X yields phenol”*).  \n",
    "\n",
    "LLMs can serve as powerful chemical entity recognizers. With well-designed prompts, an LLM can perform CNER dynamically, leveraging its contextual understanding gained during training. Unlike classical NER systems that depend on fixed vocabularies or labeled datasets, an LLM can infer roles from context. For instance, given the sentence:  \n",
    "\n",
    "*“We dissolved the sample in ethyl acetate.”*  \n",
    "\n",
    "A traditional algorithm might miss the solvent if it were not in its dictionary, whereas an LLM can infer that *ethyl acetate* functions as a solvent in this context.  \n",
    "\n",
    "**Example:** Consider the sentence:  \n",
    "*“The mixture of benzaldehyde and NaBH₄ was stirred in methanol at 0 °C.”*  \n",
    "\n",
    "A prompt to an LLM could extract:  \n",
    "- **Chemicals**: benzaldehyde, NaBH₄, methanol  \n",
    "- **Condition**: 0 °C  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpL6nZhJ9p9y",
    "outputId": "08851e35-b109-42dc-8f8d-dcd34d5397bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google in /usr/local/lib/python3.12/dist-packages (2.0.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from google) (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->google) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->google) (4.15.0)\n",
      "Chemical Compounds:\n",
      "1. Benzaldehyde\n",
      "2. NaBH4 (Sodium Borohydride)\n",
      "3. Methanol\n",
      "\n",
      "Conditions:\n",
      "1. The mixture was stirred\n",
      "2. The process was carried out at a temperature of 0°C.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI()\n",
    "\n",
    "# Input text\n",
    "text = \"The mixture of benzaldehyde and NaBH4 was stirred in methanol at 0°C.\"\n",
    "\n",
    "# Build prompt\n",
    "prompt = f\"List all chemical compounds and conditions in this text: '{text}'\"\n",
    "\n",
    "# Request completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Print answer\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTW_-9dIfCng"
   },
   "source": [
    "Let’s illustrate with a practical example using an open-source LLM or API. Suppose we have a paragraph from a paper and we want to pull out certain facts. Below, we simulate extracting information from synthetic chemistry procedure steps. We will use an LLM to find specific entities: the temperature and the starting materials in each step. First, define a list of procedure steps (as strings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8RG9l1w923B",
    "outputId": "2e3a77e9-78ee-4b19-af87-7b99f6e648b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: To a solution of aniline (0.1 mol) in 50 mL of ethanol, 0.12 mol of acetic anhydride was added dropwise at 5°C under stirring. After 2 hours, the product was filtered to yield acetanilide.\n",
      "Step 2: Weigh 2.5 g of benzaldehyde and add it to a flask with 15 mL of 95% ethanol. Add 3 g of NaOH and heat to 60°C for 30 minutes. Allow to cool and collect crystals by filtration.\n"
     ]
    }
   ],
   "source": [
    "# Example list of synthetic procedure steps\n",
    "synthetic_steps = [\n",
    "    \"To a solution of aniline (0.1 mol) in 50 mL of ethanol, 0.12 mol of acetic anhydride was added dropwise at 5°C under stirring. After 2 hours, the product was filtered to yield acetanilide.\",\n",
    "    \"Weigh 2.5 g of benzaldehyde and add it to a flask with 15 mL of 95% ethanol. Add 3 g of NaOH and heat to 60°C for 30 minutes. Allow to cool and collect crystals by filtration.\",\n",
    "    # ... more steps\n",
    "]\n",
    "\n",
    "# Preview first two steps\n",
    "for i, step in enumerate(synthetic_steps, 1):\n",
    "    print(f\"Step {i}: {step}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8up9bJlfKic"
   },
   "source": [
    "Combining this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1_Kr9yb97zL",
    "outputId": "a8018b4f-138c-4044-efbc-b1c99fe2330e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step text: To a solution of aniline (0.1  ... -> Temperature: The reaction temperature mentioned in the procedure step is 5°C.\n",
      "Step text: Weigh 2.5 g of benzaldehyde an ... -> Temperature: 60°C\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Loop through each synthetic step and extract temperature\n",
    "for step in synthetic_steps:\n",
    "    prompt = f\"Extract the reaction temperature mentioned in the following procedure step (if any):\\n{step}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    temp = response.choices[0].message.content.strip()\n",
    "    print(\"Step text:\", step[:30], \"... -> Temperature:\", temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOSnQ1pTfe64"
   },
   "source": [
    "### 5.2.2 Reaction and Methodology Mining  \n",
    "\n",
    "Extracting reactions and experimental methods from literature is one of the most valuable applications of text mining in chemistry. Systematically capturing details from patents and papers enables the creation of reaction databases, which support tasks like prediction models and trend analysis.  \n",
    "\n",
    "Traditional approaches break the text into parts: identifying reagents, products, conditions (temperature, catalysts), and actions (“added”, “heated”, “stirred”), then reconstructing structured formats (e.g., reaction SMILES or procedural steps). While accurate, these methods require heavy annotation and predefined categories.  \n",
    "\n",
    "LLMs offer a more flexible solution. With prompting, they can read free-form text and output structured data (e.g., JSON with reactants, products, solvents, and conditions) or even step-by-step procedures. This transforms unstructured text into searchable, machine-readable records.  \n",
    "\n",
    "For example, instead of manually scanning a paper, an LLM could answer:  \n",
    "*“What yield did they report for the oxidation of benzyl alcohol to benzaldehyde?”* → *“82% yield under condition X.”*  \n",
    "\n",
    "Such capabilities make literature more searchable, actionable, and directly integrable into electronic lab notebooks and ML workflows.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1FfGXmu9_Zg",
    "outputId": "fd2ce027-0c8d-4e8f-a0e4-2cd7bb1985dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"reactant\": \"Benzyl alcohol\",\n",
      "\"product\": \"Benzaldehyde\",\n",
      "\"catalyst\": \"TEMPO\",\n",
      "\"other_reagents\": [\"Dichloromethane\", \"Potassium bromide\", \"Bleach (sodium hypochlorite)\"],\n",
      "\"temperature\": [\"0°C\", \"Room temperature\"],\n",
      "\"time\": \"1 hour\",\n",
      "\"yield\": \"75%\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "procedure = (\n",
    "    \"Benzyl alcohol (1 mmol) was dissolved in 5 mL of dichloromethane. \"\n",
    "    \"TEMPO (5 mol%) and potassium bromide (0.5 mmol) were added. \"\n",
    "    \"The mixture was cooled to 0°C and 2 mmol of bleach (sodium hypochlorite) solution \"\n",
    "    \"was added dropwise. The reaction was stirred for 1 hour, warming to room temperature. \"\n",
    "    \"The organic layer was separated, dried, and evaporated to give benzaldehyde in 75% yield.\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    \"Extract the key details from this procedure as JSON with fields: \"\n",
    "    \"reactant, product, catalyst, other_reagents, temperature, time, yield.\\n\\n\"\n",
    "    f\"{procedure}\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content.strip()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuLirSCJ-If9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
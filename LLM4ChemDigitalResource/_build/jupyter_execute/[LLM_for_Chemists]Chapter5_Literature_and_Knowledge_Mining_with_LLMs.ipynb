{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKq_tqe_9rkT"
   },
   "source": [
    "Suppose we have a sentence: “The mixture of benzaldehyde and NaBH₄ was stirred in methanol at 0 °C.” We want to extract the chemicals and the temperature. We can prompt an LLM accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpL6nZhJ9p9y",
    "outputId": "5b93cdb5-0de7-48c2-a091-a8a9e70a4d18"
   },
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize client\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Input text\u001b[39;00m\n\u001b[1;32m      8\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe mixture of benzaldehyde and NaBH4 was stirred in methanol at 0°C.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_client.py:98\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     96\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI()\n",
    "\n",
    "# Input text\n",
    "text = \"The mixture of benzaldehyde and NaBH4 was stirred in methanol at 0°C.\"\n",
    "\n",
    "# Build prompt\n",
    "prompt = f\"List all chemical compounds and conditions in this text: '{text}'\"\n",
    "\n",
    "# Request completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Print answer\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8RG9l1w923B",
    "outputId": "d1e65d56-f124-48a4-835f-c2fb7766424b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: To a solution of aniline (0.1 mol) in 50 mL of ethanol, 0.12 mol of acetic anhydride was added dropwise at 5°C under stirring. After 2 hours, the product was filtered to yield acetanilide.\n",
      "Step 2: Weigh 2.5 g of benzaldehyde and add it to a flask with 15 mL of 95% ethanol. Add 3 g of NaOH and heat to 60°C for 30 minutes. Allow to cool and collect crystals by filtration.\n"
     ]
    }
   ],
   "source": [
    "# Example list of synthetic procedure steps\n",
    "synthetic_steps = [\n",
    "    \"To a solution of aniline (0.1 mol) in 50 mL of ethanol, 0.12 mol of acetic anhydride was added dropwise at 5°C under stirring. After 2 hours, the product was filtered to yield acetanilide.\",\n",
    "    \"Weigh 2.5 g of benzaldehyde and add it to a flask with 15 mL of 95% ethanol. Add 3 g of NaOH and heat to 60°C for 30 minutes. Allow to cool and collect crystals by filtration.\",\n",
    "    # ... more steps\n",
    "]\n",
    "\n",
    "# Preview first two steps\n",
    "for i, step in enumerate(synthetic_steps, 1):\n",
    "    print(f\"Step {i}: {step}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1_Kr9yb97zL",
    "outputId": "5d5e6ab4-e943-4e90-b711-b1ec1fb13011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step text: To a solution of aniline (0.1  ... -> Temperature: The reaction temperature mentioned in the procedure step is 5°C.\n",
      "Step text: Weigh 2.5 g of benzaldehyde an ... -> Temperature: The reaction temperature mentioned in the procedure is 60°C.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Loop through each synthetic step and extract temperature\n",
    "for step in synthetic_steps:\n",
    "    prompt = f\"Extract the reaction temperature mentioned in the following procedure step (if any):\\n{step}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    temp = response.choices[0].message.content.strip()\n",
    "    print(\"Step text:\", step[:30], \"... -> Temperature:\", temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1FfGXmu9_Zg",
    "outputId": "81d01146-282b-41a3-bf8d-dd53538d32fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"reactant\": \"Benzyl alcohol\",\n",
      "\"product\": \"Benzaldehyde\",\n",
      "\"catalyst\": \"TEMPO\",\n",
      "\"other_reagents\": [\"Dichloromethane\", \"Potassium bromide\", \"Bleach (sodium hypochlorite)\"],\n",
      "\"temperature\": [\"0°C\", \"Room temperature\"],\n",
      "\"time\": \"1 hour\",\n",
      "\"yield\": \"75%\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "procedure = (\n",
    "    \"Benzyl alcohol (1 mmol) was dissolved in 5 mL of dichloromethane. \"\n",
    "    \"TEMPO (5 mol%) and potassium bromide (0.5 mmol) were added. \"\n",
    "    \"The mixture was cooled to 0°C and 2 mmol of bleach (sodium hypochlorite) solution \"\n",
    "    \"was added dropwise. The reaction was stirred for 1 hour, warming to room temperature. \"\n",
    "    \"The organic layer was separated, dried, and evaporated to give benzaldehyde in 75% yield.\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    \"Extract the key details from this procedure as JSON with fields: \"\n",
    "    \"reactant, product, catalyst, other_reagents, temperature, time, yield.\\n\\n\"\n",
    "    f\"{procedure}\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.content.strip()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuLirSCJ-If9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}